{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Tent Functions for ML\n",
    "\n",
    "This is a demonstration of how to use tent functions for machine learning on a set of persistence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "from teaspoon.ML.Base import ParameterBucket, build_G, TentParameters, train_test_split, ML_via_featurization, getPercentScore\n",
    "from teaspoon.MakeData import PointCloud as gpc\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Diagrams from Manifold Test\n",
    "\n",
    "Generate persistence diagrams drawn from random point clouds of a torus, annulus, cube, three clusters, three clusters of three clusters, and spheres. See details of *testSetManifolds* function [here](http://elizabethmunch.com/code/teaspoon/namespaceteaspoon_1_1_make_data_1_1_point_cloud.html#a5d9c892f9f0a63f64437cbbde9048aeb). Select the dimension of persistence diagram to use, here we use dimension 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating torus clouds...\n",
      "Generating annuli clouds...\n",
      "Generating cube clouds...\n",
      "Generating three cluster clouds...\n",
      "Generating three clusters of three clusters clouds...\n",
      "Generating sphere clouds...\n",
      "Finished generating clouds and computing persistence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = gpc.testSetManifolds(numDgms = 100, numPts = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Version: Train Test Split & Set up Parameter Bucket\n",
    " \n",
    "### Train Test Split:\n",
    " - Choose which column (or columns) you want to use for diagrams\n",
    " - Specify which column has the training labels\n",
    " \n",
    "### Parameter Bucket\n",
    " - Need a TentParameters parameter bucket. \n",
    " - Set parameter d for mesh size in each direction.\n",
    " - Get adaptive partitions. \n",
    " - Set delta and epsilon for each partition.\n",
    " \n",
    " Note, these steps are all handled by the function *getPercentScore*. For the shortened version using this function scroll down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_col = 'Dgm1'\n",
    "if type(dgm_col) == str:\n",
    "    dgm_col = [dgm_col]\n",
    "labels_col = 'trainingLabel'\n",
    "\n",
    "# Set up parameters and adaptively partition training set\n",
    "params = TentParameters()\n",
    "\n",
    "# Run train/test split using sklearn\n",
    "D_train, D_test, L_train, L_test = train_test_split(df, df[labels_col], test_size=params.test_size, random_state = params.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.useAdaptivePart = True\n",
    "params.d = [3,3]\n",
    "\n",
    "# Concatenate training set into a pandas series:\n",
    "allDgms = pd.concat((D_train[label] for label in dgm_col))\n",
    "\n",
    "if params.useAdaptivePart == True:\n",
    "    # Hand the series to the makeAdaptivePartition function\n",
    "    params.makeAdaptivePartition(allDgms, meshingScheme = 'DV', numParts = 2)\n",
    "else:\n",
    "    # Just use the bounding box as the partition\n",
    "    params.makeAdaptivePartition(allDgms, meshingScheme = 'None')\n",
    "    \n",
    "# Assign delta and epsilon for each partition\n",
    "# If you didn't use adaptive partitioning this just assigns it to the one partition for the whole bounding box\n",
    "params.chooseDeltaEpsForPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Training Set and Partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_array = np.concatenate(list(allDgms))\n",
    "\n",
    "# Plot partitions and overlay the data\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "params.partitions.plot()\n",
    "plt.plot(dgm_array[:,0], dgm_array[:,1] - dgm_array[:,0], 'r*')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Use function from teaspoon to run ML with featurization on persistence diagrams. Takes data frame of persistence diagrams and specified column labels, computes the G matrix using *build_G*. Does classification using labels from labels_col in the data frame. Returns trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using ' + str(len(L_train)) + '/' + str(len(df)) + ' to train...')\n",
    "clf = ML_via_featurization(D_train, labels_col = labels_col, dgm_col = dgm_col, params = params, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Build G matrix for the testing set, use the model generated on the training data to predict the label. Then score the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using ' + str(len(L_test)) + '/' + str(len(df)) + ' to test...')\n",
    "listOfG = []\n",
    "for dgmColLabel in dgm_col:\n",
    "    G = build_G(D_test[dgmColLabel],params)\n",
    "    listOfG.append(G)\n",
    "\n",
    "G = np.concatenate(listOfG,axis = 1)\n",
    "\n",
    "# Compute predictions and add to DgmsDF data frame\n",
    "L_predict = pd.Series(clf.predict(G),index = L_test.index)\n",
    "df['Prediction'] = L_predict\n",
    "\n",
    "# Compute score\n",
    "score = clf.score(G,list(L_test))\n",
    "\n",
    "print('Score on testing set: ' + str(score) +\"...\\n\")\n",
    "\n",
    "print('Finished with train/test experiment.')\n",
    "\n",
    "output = {}\n",
    "output['score'] = score\n",
    "output['DgmsDF'] = df\n",
    "output['clf'] = clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short Version: Train Test Split & Set up Parameter Bucket\n",
    "\n",
    "Use function *getPercentScore* to set up parameter bucket, do train/test split and calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Beginning experiment.\n",
      "Variables in parameter bucket\n",
      "---\n",
      "feature_function : <function tent at 0x1a1bf63378>\n",
      "useAdaptivePart : True\n",
      "d : [3, 3]\n",
      "delta : 1\n",
      "epsilon : 0\n",
      "clf_model : <class 'sklearn.linear_model.ridge.RidgeClassifierCV'>\n",
      "seed : None\n",
      "test_size : 0.33\n",
      "maxPower : 1\n",
      "---\n",
      "\n",
      "Converting the data to ordinal...\n",
      "\n",
      "Parameters d, delta and epsilon have all been assigned to each partition...\n",
      "\n",
      "Using 402/600 to train...\n",
      "Training estimator.\n",
      "Making G...\n",
      "Number of features used is 4848 ...\n",
      "Checking score on training set...\n",
      "Score on training set: 0.9900497512437811.\n",
      "\n",
      "Using 198/600 to test...\n",
      "Score on testing set: 0.9090909090909091...\n",
      "\n",
      "Finished with train/test experiment.\n",
      "\n",
      "avg success rate = 0.9090909090909091\n",
      "Stdev = 0.0\n"
     ]
    }
   ],
   "source": [
    "params = TentParameters()\n",
    "params.useAdaptivePart = True\n",
    "params.d = [3,3]\n",
    "\n",
    "num_runs = 1\n",
    "yy = np.zeros((num_runs))\n",
    "for i in np.arange(num_runs):\n",
    "    xx, Dgms_train, Dgms_test = getPercentScore(df,\n",
    "                    labels_col = 'trainingLabel',\n",
    "                    dgm_col = 'Dgm1',\n",
    "                    params = params,\n",
    "                    verbose = True)\n",
    "    yy[i] = xx['score']\n",
    "\n",
    "print('\\navg success rate = {}\\nStdev = {}'.format(np.mean(yy), np.std(yy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
